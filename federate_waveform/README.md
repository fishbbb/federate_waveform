# è”é‚¦æ³¢å½¢åˆ†ç±»ç³»ç»Ÿ (Federated Waveform Classification)

åŸºäºè‡ªç ”è”é‚¦å­¦ä¹ æ¡†æ¶çš„æ³¢å½¢åˆ†ç±»ç³»ç»Ÿï¼Œæ”¯æŒä½è¡€å‹é¢„æµ‹ç­‰åŒ»ç–—åœºæ™¯åº”ç”¨ã€‚ç³»ç»Ÿé‡‡ç”¨å•è¿›ç¨‹æ¨¡æ‹Ÿå¤šå®¢æˆ·ç«¯è”é‚¦è®­ç»ƒï¼Œæ— éœ€ä¾èµ– Fed-BioMed æ¡†æ¶ã€‚

## é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªå®Œæ•´çš„è”é‚¦è¾¹ç¼˜æ™ºèƒ½ç³»ç»Ÿï¼Œç”¨äºæ³¢å½¢æ•°æ®çš„åˆ†ç±»ä»»åŠ¡ã€‚ç³»ç»Ÿæ”¯æŒï¼š

- **è‡ªç ”è”é‚¦å­¦ä¹ è®­ç»ƒ**: å•è¿›ç¨‹æ¨¡æ‹Ÿå¤šèŠ‚ç‚¹åä½œè®­ç»ƒï¼Œå®ç° FedAvg èšåˆç®—æ³•
- **ç¡¬ä»¶æ„ŸçŸ¥ä¼˜åŒ–**: è®¾å¤‡æ€§èƒ½åˆ†æå’Œèµ„æºæ„ŸçŸ¥è°ƒåº¦
- **è®¾å¤‡åœ¨çº¿æ¨¡å¼æ¨¡æ‹Ÿ**: æ”¯æŒ always_onã€mostly_onlineã€intermittentã€sporadic ç­‰åœ¨çº¿æ¨¡å¼
- **å®æ—¶ç›‘æ§**: å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹å’Œæ”¶æ•›åˆ†æ
- **å®æ—¶æ•°æ®ä¿å­˜**: è®­ç»ƒè¿‡ç¨‹ä¸­è‡ªåŠ¨ä¿å­˜æ¯è½®æ•°æ®åˆ° `results/` æ–‡ä»¶å¤¹
- **æ¨¡å‹ç‰ˆæœ¬ç®¡ç†**: æ¯è½®ä¿å­˜ current æ¨¡å‹ï¼Œè‡ªåŠ¨è·Ÿè¸ªå¹¶ä¿å­˜ best æ¨¡å‹
- **æ¨¡å‹å‹ç¼©**: é›†æˆé‡åŒ–ã€å‰ªæã€çŸ¥è¯†è’¸é¦ç­‰æ¨¡å‹å‹ç¼©æŠ€æœ¯
- **æ¨¡å‹å¯¼å‡º**: æ”¯æŒ ONNX å’Œ TensorFlow Lite æ ¼å¼

## ç›®å½•ç»“æ„

```
federate_waveform/
â”œâ”€â”€ README.md                              # æœ¬æ–‡ä»¶
â”œâ”€â”€ federated_simulation_trainer.py        # è‡ªç ”è”é‚¦è®­ç»ƒæ ¸å¿ƒæ¨¡å—ï¼ˆé‡è¦ï¼‰
â”œâ”€â”€ federated_learning_visualization.py    # å¯è§†åŒ–ç›‘æ§ç³»ç»Ÿï¼ˆFlask + SocketIOï¼‰
â”œâ”€â”€ federated_hypotension_training_plan.py # è®­ç»ƒè®¡åˆ’ï¼ˆæ•°æ®é›†ã€è®¾å¤‡ä»¿çœŸå·¥å…·å‡½æ•°ï¼‰
â”œâ”€â”€ federated_hypotension_experiment.py    # åŸºç¡€å®éªŒè„šæœ¬
â”œâ”€â”€ federated_hypotension_experiment_with_monitor.py  # å¸¦ç›‘æ§çš„å®éªŒè„šæœ¬
â”œâ”€â”€ prepare_federated_data.py              # æ•°æ®å‡†å¤‡è„šæœ¬
â”œâ”€â”€ devices.yaml                           # è®¾å¤‡é…ç½®æ–‡ä»¶ï¼ˆç¡¬ä»¶å‚æ•°ã€åœ¨çº¿æ¨¡å¼ï¼‰
â”œâ”€â”€ hardware_profiling.py                  # ç¡¬ä»¶åˆ†ææ¨¡å—
â”œâ”€â”€ resource_aware_scheduler.py            # èµ„æºæ„ŸçŸ¥è°ƒåº¦å™¨
â”œâ”€â”€ model_quantization.py                  # æ¨¡å‹é‡åŒ–æ¨¡å—
â”œâ”€â”€ model_pruning.py                       # æ¨¡å‹å‰ªææ¨¡å—
â”œâ”€â”€ model_distillation.py                  # çŸ¥è¯†è’¸é¦æ¨¡å—
â”œâ”€â”€ model_export.py                        # æ¨¡å‹å¯¼å‡ºæ¨¡å—
â”œâ”€â”€ adaptive_system.py                     # è‡ªé€‚åº”ç³»ç»Ÿæ¨¡å—
â””â”€â”€ convergence_monitoring.py              # æ”¶æ•›ç›‘æ§æ¨¡å—
```

## ç¯å¢ƒé…ç½®

### æ­¥éª¤ 1ï¼šåˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰

ä¸ºäº†éš”ç¦»é¡¹ç›®ä¾èµ–ï¼Œé¿å…ä¸å…¶ä»–é¡¹ç›®å†²çªï¼Œå¼ºçƒˆå»ºè®®ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒã€‚

#### 1.1 æ£€æŸ¥ Python ç‰ˆæœ¬

é¦–å…ˆç¡®è®¤ç³»ç»Ÿå·²å®‰è£… Python 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼ˆæ¨è 3.10ï¼‰ï¼š

```bash
# æ£€æŸ¥ Python ç‰ˆæœ¬
python3 --version
# æˆ–
python --version
```

å¦‚æœæœªå®‰è£… Python æˆ–ç‰ˆæœ¬è¿‡ä½ï¼Œè¯·å…ˆå®‰è£… Python 3.8+ã€‚

#### 1.2 åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼š

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd your_path_to/federate_waveform

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆä¼šåœ¨å½“å‰ç›®å½•ä¸‹åˆ›å»º venv æ–‡ä»¶å¤¹ï¼‰ï¼Œä¹ æƒ¯ç”¨condaå¯ä»¥è‡ªå·±æ¢
python3 -m venv venv
```

**æ³¨æ„**ï¼šå¦‚æœ `python3` å‘½ä»¤ä¸å­˜åœ¨ï¼Œå¯ä»¥å°è¯•ä½¿ç”¨ `python` å‘½ä»¤ã€‚

#### 1.3 æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ

æ ¹æ®ä½ çš„æ“ä½œç³»ç»Ÿï¼Œä½¿ç”¨ç›¸åº”çš„å‘½ä»¤æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼š

**macOS / Linux:**
```bash
source venv/bin/activate
```

**Windows:**
```bash
# PowerShell
venv\Scripts\Activate.ps1

# æˆ– CMD
venv\Scripts\activate.bat
```

æ¿€æ´»æˆåŠŸåï¼Œå‘½ä»¤è¡Œæç¤ºç¬¦å‰ä¼šæ˜¾ç¤º `(venv)` æ ‡è¯†ï¼Œä¾‹å¦‚ï¼š
```bash
(venv) user@hostname federate_waveform %
```

#### 1.4 éªŒè¯è™šæ‹Ÿç¯å¢ƒ

ç¡®è®¤è™šæ‹Ÿç¯å¢ƒå·²æ­£ç¡®æ¿€æ´»ï¼Œå¹¶æ£€æŸ¥ pip ç‰ˆæœ¬ï¼š

```bash
# æ£€æŸ¥ pip ç‰ˆæœ¬ï¼ˆå»ºè®®å‡çº§åˆ°æœ€æ–°ç‰ˆæœ¬ï¼‰
pip --version

# å‡çº§ pipï¼ˆå¯é€‰ï¼Œä½†æ¨èï¼‰
pip install --upgrade pip
```

#### 1.5 é€€å‡ºè™šæ‹Ÿç¯å¢ƒï¼ˆå¯é€‰ï¼‰

å½“ä¸å†éœ€è¦è™šæ‹Ÿç¯å¢ƒæ—¶ï¼Œå¯ä»¥é€€å‡ºï¼š

```bash
deactivate
```

**æç¤º**ï¼šæ¯æ¬¡ä½¿ç”¨é¡¹ç›®æ—¶ï¼Œéƒ½éœ€è¦å…ˆæ¿€æ´»è™šæ‹Ÿç¯å¢ƒã€‚å¯ä»¥å°†æ¿€æ´»å‘½ä»¤æ·»åŠ åˆ° shell é…ç½®æ–‡ä»¶ä¸­ï¼ˆå¦‚ `~/.zshrc` æˆ– `~/.bashrc`ï¼‰ä»¥ä¾¿å¿«é€Ÿæ¿€æ´»ã€‚

---

### æ­¥éª¤ 2ï¼šå®‰è£…é¡¹ç›®ä¾èµ–

åœ¨æ¿€æ´»è™šæ‹Ÿç¯å¢ƒåï¼ŒæŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å®‰è£…ä¾èµ–ã€‚

#### 2.1 Python ç‰ˆæœ¬è¦æ±‚

- **Python 3.8+** (æ¨è 3.10)

#### 2.2 å®‰è£…åŸºç¡€ä¾èµ–

```bash
# PyTorchï¼ˆæ ¹æ®ä½ çš„ç³»ç»Ÿé€‰æ‹© CPU æˆ– GPU ç‰ˆæœ¬ï¼‰
# macOS (MPS):
pip install torch torchvision

# Linux/Windows (CUDA):
# pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# åŸºç¡€ç§‘å­¦è®¡ç®—åº“
pip install numpy pandas scipy

# YAML é…ç½®æ–‡ä»¶è§£æ
pip install pyyaml
```

#### 2.6 ä¸€é”®å®‰è£…æ‰€æœ‰ä¾èµ–ï¼ˆæ¨èï¼‰

å¦‚æœä½ æƒ³è¦ä¸€æ¬¡æ€§å®‰è£…æ‰€æœ‰å¿…éœ€çš„ä¾èµ–ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š

```bash
# ç¡®ä¿è™šæ‹Ÿç¯å¢ƒå·²æ¿€æ´»
# source venv/bin/activate  # macOS/Linux
# æˆ– venv\Scripts\activate  # Windows

# å®‰è£…æ‰€æœ‰å¿…éœ€ä¾èµ–
pip install torch torchvision numpy pandas scipy pyyaml
pip install Flask==2.3.3 flask-socketio==5.3.5 eventlet==0.33.3
pip install psutil matplotlib scikit-learn

# å¯é€‰ï¼šæ¨¡å‹å¯¼å‡ºä¾èµ–
pip install onnx
```

#### 2.7 éªŒè¯å®‰è£…

å®‰è£…å®Œæˆåï¼Œå¯ä»¥éªŒè¯å…³é”®ä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…ï¼š

```bash
# éªŒè¯ PyTorch
python -c "import torch; print(f'PyTorch version: {torch.__version__}')"

# éªŒè¯ Flask
python -c "import flask; print(f'Flask version: {flask.__version__}')"

# éªŒè¯å…¶ä»–å…³é”®åº“
python -c "import numpy, pandas, scipy, yaml; print('All dependencies installed successfully!')"
```

### é‡è¦è¯´æ˜

âš ï¸ **æœ¬ç³»ç»Ÿä¸å†ä¾èµ– Fed-BioMed æ¡†æ¶**ã€‚æ‰€æœ‰è”é‚¦å­¦ä¹ é€»è¾‘éƒ½åœ¨ `federated_simulation_trainer.py` ä¸­è‡ªç ”å®ç°ï¼Œé‡‡ç”¨å•è¿›ç¨‹æ¨¡æ‹Ÿå¤šå®¢æˆ·ç«¯çš„æ–¹å¼ã€‚


## å¿«é€Ÿå¼€å§‹

### 0. æ•°æ®é›†è¯´æ˜

æœ¬é¡¹ç›®ä½¿ç”¨ **uci2_dataset** æ•°æ®é›†ï¼ŒåŒ…å«ï¼š
- 3ä¸ªfoldçš„CSVç‰¹å¾æ–‡ä»¶ï¼ˆ`feat_fold_0.csv`, `feat_fold_1.csv`, `feat_fold_2.csv`ï¼‰
- æ¯ä¸ªæ–‡ä»¶åŒ…å«222ä¸ªç‰¹å¾åˆ—
- æ•°æ®ä½äºé¡¹ç›®æ ¹ç›®å½•çš„ `uci2_dataset/` ç›®å½•ä¸‹

æ•°æ®é›†è¯¦ç»†ä¿¡æ¯è¯·å‚è€ƒ `Waveform-classification/help_files/UCI2_DATASET_ANALYSIS.md`

### 1. æ•°æ®å‡†å¤‡

é¦–å…ˆéœ€è¦å‡†å¤‡æ•°æ®å¹¶åˆ†å‰²åˆ°å¤šä¸ªèŠ‚ç‚¹ï¼š

```bash
cd federate_waveform
python prepare_federated_data.py
```

è¿™å°†ï¼š
1. ä» `uci2_dataset/` åŠ è½½æ‰€æœ‰foldçš„æ•°æ®
2. åˆ›å»ºä½è¡€å‹æ ‡ç­¾ï¼ˆSP < 90 æˆ– DP < 60ï¼‰
3. åˆå¹¶æ‰€æœ‰foldå¹¶åˆ†å‰²ä¸ºè®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†
4. å°†è®­ç»ƒæ•°æ®åˆ†é…åˆ°å¤šä¸ªèŠ‚ç‚¹ï¼ˆnode_1, node_2, node_3ï¼‰
5. åˆ›å»º `federated_data/` ç›®å½•ï¼ŒåŒ…å«æ¯ä¸ªèŠ‚ç‚¹çš„æ•°æ®æ–‡ä»¶

**è¾“å‡ºæ–‡ä»¶**ï¼š
- `federated_data/node_1/train.pth` - èŠ‚ç‚¹1çš„è®­ç»ƒ/éªŒè¯æ•°æ®åˆ†å‰²
- `federated_data/node_2/train.pth` - èŠ‚ç‚¹2çš„è®­ç»ƒ/éªŒè¯æ•°æ®åˆ†å‰²
- `federated_data/node_3/train.pth` - èŠ‚ç‚¹3çš„è®­ç»ƒ/éªŒè¯æ•°æ®åˆ†å‰²
- `federated_data/test.pth` - æµ‹è¯•é›†æ•°æ®

**æ³¨æ„**: ç¡®ä¿ `uci2_dataset/` ç›®å½•åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼Œä¸”åŒ…å« `feat_fold_0.csv`, `feat_fold_1.csv`, `feat_fold_2.csv` æ–‡ä»¶ã€‚

### 2. é…ç½®è®¾å¤‡å‚æ•°

ç¼–è¾‘ `devices.yaml` æ–‡ä»¶ï¼Œé…ç½®æ¯ä¸ªèŠ‚ç‚¹çš„ç¡¬ä»¶å‚æ•°å’Œåœ¨çº¿æ¨¡å¼ï¼š

```yaml
devices:
  - id: node_1
    type: "phone_low_end"
    compute_power: "low"
    online_pattern: "intermittent"    # é—´æ­‡åœ¨çº¿ï¼ˆçº¦40%è½®æ¬¡å‚ä¸ï¼‰
    # ... å…¶ä»–å‚æ•°

  - id: node_2
    type: "tablet_mid"
    compute_power: "medium"
    online_pattern: "mostly_online"   # å¤§éƒ¨åˆ†æ—¶é—´åœ¨çº¿ï¼ˆçº¦80%è½®æ¬¡å‚ä¸ï¼‰
    # ... å…¶ä»–å‚æ•°

  - id: node_3
    type: "edge_gateway"
    compute_power: "high"
    online_pattern: "always_on"       # å§‹ç»ˆåœ¨çº¿ï¼ˆ100%å‚ä¸ï¼‰
    # ... å…¶ä»–å‚æ•°
```

### 3. å¯åŠ¨å¯è§†åŒ–ç›‘æ§ç³»ç»Ÿ

```bash
# å¯åŠ¨å¯è§†åŒ–ç›‘æ§æœåŠ¡å™¨
python federated_learning_visualization.py
```

è®¿é—® `http://localhost:5002` æ‰“å¼€æ§åˆ¶é¢æ¿ï¼Œå¯ä»¥ï¼š
- **æ¿€æ´»èŠ‚ç‚¹**: ç‚¹å‡»"å¯åŠ¨èŠ‚ç‚¹"æŒ‰é’®æ¿€æ´» node_1, node_2, node_3
- **é…ç½®è®­ç»ƒ**: è®¾ç½®è®­ç»ƒè½®æ•°ã€æ‰¹æ¬¡å¤§å°ã€å­¦ä¹ ç‡ç­‰å‚æ•°
- **å¯ç”¨å‹ç¼©**ï¼ˆå¯é€‰ï¼‰: åœ¨è®­ç»ƒé…ç½®ä¸­å¯ç”¨æ¨¡å‹é‡åŒ–ã€å‰ªæç­‰å‹ç¼©åŠŸèƒ½
- **å¯åŠ¨è®­ç»ƒ**: ç‚¹å‡»"å¼€å§‹è®­ç»ƒ"æŒ‰é’®å¯åŠ¨è”é‚¦è®­ç»ƒ
- **å®æ—¶ç›‘æ§**: æŸ¥çœ‹è®­ç»ƒè¿›åº¦ã€æŒ‡æ ‡æ›²çº¿ã€èŠ‚ç‚¹çŠ¶æ€ç­‰
- **å®æ—¶æ•°æ®**: è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ•°æ®è‡ªåŠ¨ä¿å­˜åˆ° `results/` æ–‡ä»¶å¤¹
- **æ•°æ®åˆ†æ**: æŸ¥çœ‹è®­ç»ƒå†å²å’Œæ”¶æ•›åˆ†æ

**è®­ç»ƒè¿‡ç¨‹ä¸­çš„è‡ªåŠ¨ä¿å­˜**:
- æ¯è½®è®­ç»ƒå®Œæˆåï¼Œè‡ªåŠ¨ä¿å­˜åˆ° `results/training_data/round_N.json`
- æ¯è½®æ¨¡å‹è‡ªåŠ¨ä¿å­˜åˆ° `results/models/current_round_N.pth`
- æœ€ä½³æ¨¡å‹è‡ªåŠ¨è·Ÿè¸ªå¹¶ä¿å­˜åˆ° `results/models/best_model.pth`
- å¦‚æœå¯ç”¨å‹ç¼©ï¼Œå‹ç¼©æ¨¡å‹ä¿å­˜åˆ° `results/compressed_models/round_N/`

**è¯¦ç»†ä½¿ç”¨è¯´æ˜è¯·å‚è€ƒï¼š[å¯è§†åŒ–ç›‘æ§ç³»ç»Ÿä½¿ç”¨æ‰‹å†Œ](VISUALIZATION_USER_MANUAL.md)**

### 4. è¿è¡Œå®éªŒï¼ˆå‘½ä»¤è¡Œæ–¹å¼ï¼‰

#### åŸºç¡€å®éªŒ

```bash
python federated_hypotension_experiment.py
```

#### å¸¦ç›‘æ§çš„å®éªŒ

```bash
python federated_hypotension_experiment_with_monitor.py
```

è®¿é—® `http://localhost:5000` æŸ¥çœ‹å®æ—¶ç›‘æ§ç•Œé¢ã€‚

## åŠŸèƒ½æ¨¡å—è¯´æ˜

### 1. è‡ªç ”è”é‚¦è®­ç»ƒæ ¸å¿ƒ (`federated_simulation_trainer.py`)

è¿™æ˜¯ç³»ç»Ÿçš„æ ¸å¿ƒæ¨¡å—ï¼Œå®ç°äº†å®Œæ•´çš„è”é‚¦å­¦ä¹ è®­ç»ƒå¾ªç¯ï¼š

- **å®¢æˆ·ç«¯æŠ½è±¡**: `FederatedClient` ç±»å°è£…å•ä¸ªå®¢æˆ·ç«¯çš„è®­ç»ƒé€»è¾‘
- **FedAvg èšåˆ**: `federated_average()` å‡½æ•°å®ç°æ¨¡å‹èšåˆ
- **è®­ç»ƒå¾ªç¯**: `run_federated_training()` å‡½æ•°åè°ƒæ•´ä¸ªè®­ç»ƒè¿‡ç¨‹
- **è®¾å¤‡ä»¿çœŸ**: æ ¹æ® `devices.yaml` é…ç½®æ¨¡æ‹Ÿä¸åŒè®¾å¤‡çš„è®¡ç®—èƒ½åŠ›å’Œåœ¨çº¿æ¨¡å¼

### 2. ç¡¬ä»¶æ„ŸçŸ¥ä¼˜åŒ–

ç³»ç»Ÿæ”¯æŒæ ¹æ®è®¾å¤‡æ€§èƒ½è‡ªåŠ¨è°ƒæ•´è®­ç»ƒå‚æ•°ï¼š

```python
# devices.yaml ä¸­é…ç½®
compute_power: "low"      # low, medium, high
cpu_threads: 1            # PyTorch çº¿ç¨‹æ•°
max_batch_size: 32        # æœ€å¤§æ‰¹æ¬¡å¤§å°
simulated_compute_delay_ms: 180  # æ¨¡æ‹Ÿè®¡ç®—å»¶è¿Ÿ
```

### 3. è®¾å¤‡åœ¨çº¿æ¨¡å¼

æ”¯æŒå››ç§åœ¨çº¿æ¨¡å¼ï¼Œæ¨¡æ‹ŸçœŸå®åœºæ™¯ä¸­çš„è®¾å¤‡å¯ç”¨æ€§ï¼š

- `always_on`: 100% å‚ä¸ç‡ï¼ˆå¦‚è¾¹ç¼˜ç½‘å…³ï¼‰
- `mostly_online`: çº¦ 80% å‚ä¸ç‡ï¼ˆå¦‚å¹³æ¿è®¾å¤‡ï¼‰
- `intermittent`: çº¦ 40% å‚ä¸ç‡ï¼ˆå¦‚ä½ç«¯æ‰‹æœºï¼‰
- `sporadic`: çº¦ 20% å‚ä¸ç‡ï¼ˆå¦‚IoTè®¾å¤‡ï¼‰

è®­ç»ƒé¡ºåºæŒ‰åœ¨çº¿æ¨¡å¼çš„å¯é æ€§ä¼˜å…ˆçº§æ’åºï¼š`always_on` > `mostly_online` > `intermittent` > `sporadic`

### 4. æ¨¡å‹å‹ç¼©å’Œå¯¼å‡º

ç³»ç»Ÿæ”¯æŒå¤šç§æ¨¡å‹ä¼˜åŒ–æŠ€æœ¯ï¼Œå¯ä»¥åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è‡ªåŠ¨åº”ç”¨ï¼š

#### 4.1 å¯ç”¨æ¨¡å‹å‹ç¼©

åœ¨è®­ç»ƒé…ç½®ä¸­å¯ç”¨å‹ç¼©åŠŸèƒ½ï¼š

```python
from federated_simulation_trainer import run_federated_training

config = {
    'round_limit': 5,
    'training_args': {...},
    'model_args': {...}
}

# å‹ç¼©é…ç½®
compression_config = {
    'quantization': {
        'enabled': True,
        'type': 'dynamic'  # æˆ– 'static'
    },
    'pruning': {
        'enabled': True,
        'ratio': 0.3,      # å‰ªææ¯”ä¾‹
        'type': 'l1_unstructured'  # æˆ– 'l2_unstructured'
    }
}

result = run_federated_training(
    config=config,
    save_results=True,
    enable_compression=True,
    compression_config=compression_config
)
```

#### 4.2 æ¨¡å‹é‡åŒ–

**åŠ¨æ€é‡åŒ–**ï¼ˆæ¨èï¼Œæ— éœ€æ ¡å‡†æ•°æ®ï¼‰:
```python
from model_quantization import ModelQuantizer

quantizer = ModelQuantizer()
quantized_model = quantizer.quantize_model(
    model=original_model,
    quantization_type='dynamic'
)
```

**é™æ€é‡åŒ–**ï¼ˆéœ€è¦æ ¡å‡†æ•°æ®ï¼Œå‹ç¼©ç‡æ›´é«˜ï¼‰:
```python
quantized_model = quantizer.quantize_model(
    model=original_model,
    quantization_type='static',
    calibration_data=calibration_loader
)
```

#### 4.3 æ¨¡å‹å‰ªæ

```python
from model_pruning import ModelPruner

pruner = ModelPruner()
pruned_model = pruner.prune_model(
    model=original_model,
    pruning_ratio=0.3,  # å‰ªæ30%çš„å‚æ•°
    pruning_type='l1_unstructured'  # æˆ– 'l2_unstructured'
)

# è·å–å‰ªæç»Ÿè®¡
stats = pruner.get_pruning_statistics(original_model, pruned_model)
print(f"å‚æ•°å‡å°‘: {stats['parameter_reduction_percent']:.2f}%")
```

#### 4.4 çŸ¥è¯†è’¸é¦

```python
from model_distillation import KnowledgeDistillation

# åˆ›å»ºæ•™å¸ˆæ¨¡å‹ï¼ˆå¤§æ¨¡å‹ï¼‰å’Œå­¦ç”Ÿæ¨¡å‹ï¼ˆå°æ¨¡å‹ï¼‰
teacher_model = myecgnet(pretrained=False, num_classes=1)
student_model = myecgnet(pretrained=False, num_classes=1)  # å¯ä»¥æ˜¯æ›´å°çš„æ¶æ„

distiller = KnowledgeDistillation(
    teacher_model=teacher_model,
    student_model=student_model,
    temperature=3.0,  # æ¸©åº¦å‚æ•°
    alpha=0.7         # è’¸é¦æŸå¤±æƒé‡
)

# è®­ç»ƒå­¦ç”Ÿæ¨¡å‹
for epoch in range(num_epochs):
    for data, labels in train_loader:
        result = distiller.train_step(data, labels, optimizer)
        print(f"Loss: {result['loss']:.4f}, Accuracy: {result['accuracy']:.4f}")
```

#### 4.5 æ¨¡å‹å¯¼å‡º

```python
from model_export import ModelExporter

exporter = ModelExporter()
exported_files = exporter.export_all_formats(
    model=result['best_model'],  # ä½¿ç”¨æœ€ä½³æ¨¡å‹
    input_shape=(1, 1, 1, 1000),
    output_dir='./models',
    model_name='hypotension_model'
)
# è¾“å‡º: {'onnx': 'models/hypotension_model.onnx', 'torchscript': '...', ...}
```

è¯¦ç»†ä½¿ç”¨æ–¹æ³•è¯·å‚è€ƒå„æ¨¡å—çš„æ–‡æ¡£å­—ç¬¦ä¸²ã€‚

## é…ç½®è¯´æ˜

### è®­ç»ƒé…ç½®

åœ¨å¯è§†åŒ–ç•Œé¢æˆ–ä»£ç ä¸­å¯ä»¥é…ç½®ï¼š

- `rounds`: è”é‚¦è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤5ï¼‰
- `batch_size`: æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤128ï¼‰
- `learning_rate`: å­¦ä¹ ç‡ï¼ˆé»˜è®¤4e-5ï¼‰
- `epochs`: æ¯è½®è®­ç»ƒçš„æœ¬åœ°epochæ•°ï¼ˆé»˜è®¤1ï¼‰

### è®¾å¤‡é…ç½® (`devices.yaml`)

æ¯ä¸ªè®¾å¤‡å¯ä»¥é…ç½®ï¼š

- `online_pattern`: åœ¨çº¿æ¨¡å¼ï¼ˆalways_on, mostly_online, intermittent, sporadicï¼‰
- `compute_power`: è®¡ç®—èƒ½åŠ›ï¼ˆlow, medium, highï¼‰
- `cpu_threads`: CPUçº¿ç¨‹æ•°
- `max_batch_size`: æœ€å¤§æ‰¹æ¬¡å¤§å°
- `simulated_compute_delay_ms`: æ¨¡æ‹Ÿè®¡ç®—å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
- `upload_latency_ms`: ä¸Šä¼ å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
- `bandwidth_kbps`: å¸¦å®½ï¼ˆKbpsï¼‰

## ğŸ“Š å¯äº§å‡ºçš„æ•°æ®/æ¨¡å‹ï¼ˆç”¨äºæŠ¥å‘Šï¼‰

è®­ç»ƒå®Œæˆåï¼Œç³»ç»Ÿå¯ä»¥äº§å‡ºä»¥ä¸‹æ•°æ®ç”¨äºæ’°å†™æŠ¥å‘Šï¼š

### 1. è®­ç»ƒå†å²æ•°æ®ï¼ˆå®æ—¶ä¿å­˜ï¼‰

**ä½ç½®**: 
- `results/training_data/training_history.json` (å®æ—¶æ›´æ–°)
- `results/training_data/round_N.json` (æ¯è½®å•ç‹¬ä¿å­˜)
- `run_federated_training()` è¿”å›çš„ `result['history']`

**å†…å®¹**:
```python
training_history = [
    {
        'round': 0,
        'global_metrics': {
            'loss': 0.5234,
            'val_loss': 0.5123,
            'accuracy': 0.7567,
            'f1': 0.7234
        },
        'client_metrics': {
            'node_1': {'loss': 0.5, 'accuracy': 0.75, 'f1': 0.72, ...},
            'node_2': {'loss': 0.55, 'accuracy': 0.74, 'f1': 0.71, ...},
            'node_3': {'loss': 0.52, 'accuracy': 0.76, 'f1': 0.73, ...}
        },
        'time': 125.3  # æœ¬è½®è€—æ—¶ï¼ˆç§’ï¼‰
    },
    # ... æ›´å¤šè½®æ¬¡
]
```

**ç”¨é€”**: 
- ç»˜åˆ¶è®­ç»ƒæ›²çº¿ï¼ˆLossã€Accuracyã€F1 Scoreï¼‰
- åˆ†ææ”¶æ•›é€Ÿåº¦
- å¯¹æ¯”ä¸åŒèŠ‚ç‚¹çš„æ€§èƒ½
- è®¡ç®—å¹³å‡è®­ç»ƒæ—¶é—´

### 2. å…¨å±€æŒ‡æ ‡æ•°æ®ï¼ˆå®æ—¶ä¿å­˜ï¼‰

**ä½ç½®**: 
- `results/training_data/round_N.json` (æ¯è½®å®æ—¶ä¿å­˜)
- `results/training_data/training_history.json` (å®æ—¶æ›´æ–°)
- `monitor.state['global_metrics']` æˆ– `result['history']` ä¸­æ¯è½®çš„ `global_metrics`

**å†…å®¹**:
```python
global_metrics = {
    'loss': [0.5234, 0.5123, 0.5012, ...],      # æ¯è½®çš„loss
    'f1': [0.7234, 0.7345, 0.7456, ...],       # æ¯è½®çš„F1 score
    'accuracy': [0.7567, 0.7654, 0.7743, ...],  # æ¯è½®çš„accuracy
    'rounds': [0, 1, 2, 3, 4]                    # è½®æ¬¡ç´¢å¼•
}
```

**ç”¨é€”**:
- ç»˜åˆ¶å…¨å±€æŒ‡æ ‡æ›²çº¿
- åˆ†ææ¨¡å‹æ”¶æ•›è¶‹åŠ¿
- è¯„ä¼°æœ€ç»ˆæ¨¡å‹æ€§èƒ½

### 3. æ¨¡å‹æ–‡ä»¶ï¼ˆè‡ªåŠ¨ä¿å­˜ï¼‰

**ä½ç½®**: `results/models/` ç›®å½•

**å†…å®¹**: 
- **æ¯è½®æ¨¡å‹**: `current_round_N.pth` - æ¯è½®è®­ç»ƒå®Œæˆåçš„æ¨¡å‹
- **æœ€ä½³æ¨¡å‹**: `best_model.pth` - è‡ªåŠ¨è·Ÿè¸ªçš„æœ€ä½³æ¨¡å‹ï¼ˆåŸºäº F1 Scoreï¼‰
- **æœ€ä½³æ¨¡å‹ä¿¡æ¯**: `best_model_info.json` - åŒ…å«æœ€ä½³è½®æ¬¡ã€F1 Scoreã€Accuracy ç­‰
- **æœ€ç»ˆæ¨¡å‹**: `final_model.pth` - è®­ç»ƒç»“æŸæ—¶çš„æ¨¡å‹

**è‡ªåŠ¨ä¿å­˜æœºåˆ¶**:
- æ¯è½®è®­ç»ƒå®Œæˆåï¼Œè‡ªåŠ¨ä¿å­˜ `current_round_N.pth`
- å¦‚æœå½“å‰è½®çš„ F1 Score è¶…è¿‡å†å²æœ€ä½³å€¼ï¼Œè‡ªåŠ¨æ›´æ–° `best_model.pth`
- è®­ç»ƒç»“æŸåï¼Œä¿å­˜ `final_model.pth`

**ä½¿ç”¨æ–¹å¼**:
```python
# åŠ è½½æœ€ä½³æ¨¡å‹
best_model_state = torch.load('results/models/best_model.pth')

# æŸ¥çœ‹æœ€ä½³æ¨¡å‹ä¿¡æ¯
import json
with open('results/models/best_model_info.json', 'r') as f:
    best_info = json.load(f)
print(f"Best model at round {best_info['round']}, F1: {best_info['f1_score']:.4f}")

# å¯¼å‡ºæœ€ä½³æ¨¡å‹
from model_export import ModelExporter
exporter = ModelExporter()
exporter.export_to_onnx(
    model=best_model_state,  # éœ€è¦å…ˆåŠ è½½åˆ°æ¨¡å‹å®ä¾‹
    input_shape=(1, 1, 1, 1000),
    output_path='best_model.onnx'
)
```

**ç”¨é€”**:
- æ¨¡å‹éƒ¨ç½²
- æ¨¡å‹æ€§èƒ½è¯„ä¼°
- æ¨¡å‹å‹ç¼©å®éªŒï¼ˆé‡åŒ–ã€å‰ªæç­‰ï¼‰

### 4. æœ€ç»ˆè¯„ä¼°æŒ‡æ ‡ï¼ˆè‡ªåŠ¨ä¿å­˜ï¼‰

**ä½ç½®**: 
- `results/training_data/final_metrics.json` (è‡ªåŠ¨ä¿å­˜)
- `run_federated_training()` è¿”å›çš„ `result['final_metrics']`

**å†…å®¹**:
```python
final_metrics = {
    'node_1': {
        'loss': 0.5012,
        'accuracy': 0.7743,
        'f1': 0.7456,
        'samples': 109492
    },
    'node_2': {...},
    'node_3': {...}
}
```

**ç”¨é€”**:
- æŠ¥å‘Šæœ€ç»ˆæ¨¡å‹åœ¨å„èŠ‚ç‚¹ä¸Šçš„æ€§èƒ½
- å¯¹æ¯”ä¸åŒèŠ‚ç‚¹çš„æ•°æ®åˆ†å¸ƒå½±å“
- è¯„ä¼°æ¨¡å‹æ³›åŒ–èƒ½åŠ›

### 5. è®­ç»ƒæ€»ç»“ï¼ˆè‡ªåŠ¨ä¿å­˜ï¼‰

**ä½ç½®**: `results/training_data/training_summary.json`

**å†…å®¹**:
```json
{
    "total_rounds": 5,
    "best_round": 3,
    "best_f1_score": 0.7456,
    "final_metrics": {...},
    "training_time": 625.3,
    "timestamp": "2024-12-09 18:30:00"
}
```

### 6. ç›‘æ§çŠ¶æ€æ•°æ®

**ä½ç½®**: `monitor.state` æˆ–é€šè¿‡ `monitor.get_state()` è·å–

**å†…å®¹**:
```python
{
    'experiment_running': False,
    'current_round': 4,
    'total_rounds': 5,
    'start_time': '2024-12-09T18:00:00',
    'end_time': '2024-12-09T18:15:30',
    'experiment_config': {...},
    'nodes': {
        'node_1': {
            'status': 'completed',
            'data_size': 109492,
            'metrics': {...}
        },
        # ...
    },
    'round_history': [...],  # æ¯è½®çš„è¯¦ç»†å†å²
    'global_metrics': {...},  # å…¨å±€æŒ‡æ ‡æ•°ç»„
    'detailed_status': {
        'round_start_time': '...',
        'round_times': [125.3, 118.7, ...],  # æ¯è½®è€—æ—¶
        'current_metrics': {...},
        'nodes_training': {...}
    }
}
```

**ä¿å­˜æ–¹å¼**:
```python
import json
state = monitor.get_state()
with open('training_state.json', 'w') as f:
    json.dump(state, f, indent=2)
```

**ç”¨é€”**:
- å®Œæ•´çš„è®­ç»ƒè¿‡ç¨‹è®°å½•
- èŠ‚ç‚¹å‚ä¸æƒ…å†µåˆ†æ
- è®­ç»ƒæ—¶é—´ç»Ÿè®¡
- å¯è§†åŒ–æ•°æ®æº

### 7. å‹ç¼©æ¨¡å‹æ–‡ä»¶ï¼ˆå¦‚æœå¯ç”¨å‹ç¼©ï¼‰

**ä½ç½®**: `results/compressed_models/round_N/`

**å†…å®¹**:
- `quantized_model.pth`: é‡åŒ–åçš„æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨é‡åŒ–ï¼‰
- `pruned_model.pth`: å‰ªæåçš„æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨å‰ªæï¼‰

**è¯´æ˜**: æ¯è½®è®­ç»ƒå®Œæˆåï¼Œå¦‚æœå¯ç”¨äº†å‹ç¼©åŠŸèƒ½ï¼Œä¼šè‡ªåŠ¨ç”Ÿæˆå‹ç¼©æ¨¡å‹å¹¶ä¿å­˜ã€‚

### 8. å¯è§†åŒ–å›¾è¡¨æ•°æ®

**é€šè¿‡å‰ç«¯ç•Œé¢å¯¼å‡º**:
- è®­ç»ƒæ›²çº¿å›¾ï¼ˆLossã€Accuracyã€F1 Scoreï¼‰
- èŠ‚ç‚¹çŠ¶æ€å›¾
- æ”¶æ•›åˆ†æå›¾

**æˆ–ä½¿ç”¨ä»£ç ç”Ÿæˆ**:
```python
from convergence_monitoring import ConvergenceMonitor

monitor = ConvergenceMonitor()
# ä» training_history å¡«å……æ•°æ®
for round_data in training_history:
    monitor.record_round(
        round_num=round_data['round'],
        loss=round_data['global_metrics']['loss'],
        f1_score=round_data['global_metrics']['f1'],
        accuracy=round_data['global_metrics']['accuracy']
    )

# ç”Ÿæˆå›¾è¡¨
monitor.plot_convergence_curves(save_path='convergence.png')

# ç”ŸæˆæŠ¥å‘Š
report = monitor.get_convergence_report()
```

### 9. æ¨¡å‹å¯¼å‡ºæ–‡ä»¶

ä½¿ç”¨ `model_export.py` æ¨¡å—å¯ä»¥å¯¼å‡ºï¼š

- **PyTorch æ¨¡å‹** (`.pth`): å®Œæ•´æ¨¡å‹çŠ¶æ€
- **ONNX æ¨¡å‹** (`.onnx`): è·¨å¹³å°æ¨ç†æ ¼å¼
- **TorchScript æ¨¡å‹** (`.pt`): PyTorch åºåˆ—åŒ–æ ¼å¼
- **TensorFlow Lite æ¨¡å‹** (`.tflite`): ç§»åŠ¨ç«¯éƒ¨ç½²æ ¼å¼

**ç¤ºä¾‹**:
```python
from model_export import ModelExporter

exporter = ModelExporter()
exported_files = exporter.export_all_formats(
    model=result['global_model'],
    input_shape=(1, 1, 1, 1000),
    output_dir='./models',
    model_name='hypotension_model'
)
# è¾“å‡º: {'onnx': 'models/hypotension_model.onnx', ...}
```

### 10. æ•°æ®ç»Ÿè®¡ä¿¡æ¯

**èŠ‚ç‚¹æ•°æ®åˆ†å¸ƒ**:
- æ¯ä¸ªèŠ‚ç‚¹çš„æ ·æœ¬æ•°é‡ï¼ˆä» `train.pth` æ–‡ä»¶è¯»å–ï¼‰
- æ­£è´Ÿæ ·æœ¬æ¯”ä¾‹ï¼ˆä½è¡€å‹ vs æ­£å¸¸ï¼‰
- æ•°æ®ç‰¹å¾ç»Ÿè®¡

**è®­ç»ƒç»Ÿè®¡**:
- æ€»è®­ç»ƒæ—¶é—´
- æ¯è½®å¹³å‡æ—¶é—´
- èŠ‚ç‚¹å‚ä¸ç‡ï¼ˆæ ¹æ® online_pattern è®¡ç®—ï¼‰

## è¾“å‡ºæ–‡ä»¶ç»“æ„

è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨åœ¨ `results/` æ–‡ä»¶å¤¹ä¸­ä¿å­˜ä»¥ä¸‹æ•°æ®ï¼š

```
results/
â”œâ”€â”€ models/                          # æ¨¡å‹æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ current_round_0.pth         # ç¬¬1è½®çš„å½“å‰æ¨¡å‹
â”‚   â”œâ”€â”€ current_round_1.pth         # ç¬¬2è½®çš„å½“å‰æ¨¡å‹
â”‚   â”œâ”€â”€ current_round_2.pth         # ç¬¬3è½®çš„å½“å‰æ¨¡å‹
â”‚   â”œâ”€â”€ ...                          # æ¯è½®éƒ½ä¼šä¿å­˜ current æ¨¡å‹
â”‚   â”œâ”€â”€ best_model.pth              # æœ€ä½³æ¨¡å‹ï¼ˆè‡ªåŠ¨æ›´æ–°ï¼‰
â”‚   â”œâ”€â”€ best_model_info.json        # æœ€ä½³æ¨¡å‹ä¿¡æ¯ï¼ˆè½®æ¬¡ã€æŒ‡æ ‡ç­‰ï¼‰
â”‚   â””â”€â”€ final_model.pth             # æœ€ç»ˆæ¨¡å‹ï¼ˆè®­ç»ƒç»“æŸæ—¶çš„æ¨¡å‹ï¼‰
â”‚
â”œâ”€â”€ training_data/                   # è®­ç»ƒæ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ round_0.json                 # ç¬¬1è½®çš„è¯¦ç»†æ•°æ®
â”‚   â”œâ”€â”€ round_1.json                 # ç¬¬2è½®çš„è¯¦ç»†æ•°æ®
â”‚   â”œâ”€â”€ round_2.json                 # ç¬¬3è½®çš„è¯¦ç»†æ•°æ®
â”‚   â”œâ”€â”€ ...                          # æ¯è½®éƒ½ä¼šå®æ—¶ä¿å­˜
â”‚   â”œâ”€â”€ training_history.json        # å®Œæ•´è®­ç»ƒå†å²ï¼ˆæ¯è½®æ›´æ–°ï¼‰
â”‚   â”œâ”€â”€ final_metrics.json           # æœ€ç»ˆè¯„ä¼°æŒ‡æ ‡
â”‚   â””â”€â”€ training_summary.json        # è®­ç»ƒæ€»ç»“ï¼ˆæœ€ä½³è½®æ¬¡ã€æ€»æ—¶é—´ç­‰ï¼‰
â”‚
â”œâ”€â”€ compressed_models/               # å‹ç¼©æ¨¡å‹ç›®å½•ï¼ˆå¦‚æœå¯ç”¨å‹ç¼©ï¼‰
â”‚   â”œâ”€â”€ round_0/
â”‚   â”‚   â”œâ”€â”€ quantized_model.pth     # é‡åŒ–æ¨¡å‹
â”‚   â”‚   â””â”€â”€ pruned_model.pth        # å‰ªææ¨¡å‹
â”‚   â”œâ”€â”€ round_1/
â”‚   â”‚   â”œâ”€â”€ quantized_model.pth
â”‚   â”‚   â””â”€â”€ pruned_model.pth
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ figures/                         # å¯è§†åŒ–å›¾è¡¨ï¼ˆæ‰‹åŠ¨ç”Ÿæˆï¼‰
    â”œâ”€â”€ convergence_curves.png       # æ”¶æ•›æ›²çº¿
    â”œâ”€â”€ loss_curve.png               # Loss æ›²çº¿
    â”œâ”€â”€ accuracy_curve.png          # Accuracy æ›²çº¿
    â””â”€â”€ f1_curve.png                 # F1 Score æ›²çº¿
```

### å®æ—¶æ•°æ®ä¿å­˜è¯´æ˜

- **æ¯è½®è®­ç»ƒå®Œæˆåç«‹å³ä¿å­˜**:
  - `round_N.json`: åŒ…å«è¯¥è½®çš„å…¨å±€æŒ‡æ ‡ã€å®¢æˆ·ç«¯æŒ‡æ ‡ã€è®­ç»ƒæ—¶é—´ç­‰
  - `current_round_N.pth`: è¯¥è½®çš„æ¨¡å‹çŠ¶æ€å­—å…¸
  - `training_history.json`: è‡ªåŠ¨æ›´æ–°ï¼ŒåŒ…å«æ‰€æœ‰è½®æ¬¡çš„å†å²

- **æœ€ä½³æ¨¡å‹è‡ªåŠ¨è·Ÿè¸ª**:
  - ç³»ç»Ÿä½¿ç”¨ **F1 Score** ä½œä¸ºä¸»è¦æŒ‡æ ‡æ¥åˆ¤æ–­æœ€ä½³æ¨¡å‹
  - å½“æŸè½®çš„ F1 Score è¶…è¿‡å½“å‰æœ€ä½³å€¼æ—¶ï¼Œè‡ªåŠ¨ä¿å­˜ä¸º `best_model.pth`
  - åŒæ—¶æ›´æ–° `best_model_info.json`ï¼Œè®°å½•æœ€ä½³è½®æ¬¡å’ŒæŒ‡æ ‡

- **è®­ç»ƒç»“æŸåä¿å­˜**:
  - `final_model.pth`: æœ€åä¸€è½®çš„æ¨¡å‹
  - `final_metrics.json`: æ‰€æœ‰èŠ‚ç‚¹çš„æœ€ç»ˆè¯„ä¼°æŒ‡æ ‡
  - `training_summary.json`: è®­ç»ƒæ€»ç»“ï¼ŒåŒ…æ‹¬æœ€ä½³è½®æ¬¡ã€æ€»è®­ç»ƒæ—¶é—´ç­‰

## æŠ¥å‘Šæ’°å†™å»ºè®®

åŸºäºäº§å‡ºçš„æ•°æ®ï¼Œå¯ä»¥æ’°å†™ä»¥ä¸‹å†…å®¹ï¼š

1. **å®éªŒè®¾ç½®**
   - æ•°æ®é›†æè¿°ï¼ˆuci2_datasetï¼Œæ ·æœ¬æ•°ï¼Œç‰¹å¾æ•°ï¼‰
   - è®¾å¤‡é…ç½®ï¼ˆ3ä¸ªèŠ‚ç‚¹ï¼Œä¸åŒè®¡ç®—èƒ½åŠ›å’Œåœ¨çº¿æ¨¡å¼ï¼‰
   - è®­ç»ƒå‚æ•°ï¼ˆè½®æ•°ã€æ‰¹æ¬¡å¤§å°ã€å­¦ä¹ ç‡ï¼‰
   - æ¨¡å‹å‹ç¼©é…ç½®ï¼ˆå¦‚æœå¯ç”¨ï¼‰

2. **å®éªŒç»“æœ**
   - è®­ç»ƒæ›²çº¿å›¾ï¼ˆä½¿ç”¨ `results/training_data/training_history.json`ï¼‰
   - æœ€ç»ˆæ€§èƒ½æŒ‡æ ‡ï¼ˆä½¿ç”¨ `results/training_data/final_metrics.json`ï¼‰
   - æœ€ä½³æ¨¡å‹æ€§èƒ½ï¼ˆä½¿ç”¨ `results/models/best_model_info.json`ï¼‰
   - æ”¶æ•›åˆ†æï¼ˆä½¿ç”¨æ¯è½®çš„ `round_N.json` æ•°æ®ï¼‰

3. **æ€§èƒ½åˆ†æ**
   - ä¸åŒèŠ‚ç‚¹çš„æ€§èƒ½å¯¹æ¯”ï¼ˆä» `round_N.json` ä¸­çš„ `client_metrics` æå–ï¼‰
   - åœ¨çº¿æ¨¡å¼å¯¹è®­ç»ƒçš„å½±å“ï¼ˆå¯¹æ¯”ä¸åŒ online_patternï¼‰
   - è®­ç»ƒæ—¶é—´ç»Ÿè®¡ï¼ˆä» `training_summary.json` è·å–ï¼‰
   - æœ€ä½³æ¨¡å‹å‡ºç°æ—¶æœºï¼ˆä» `best_model_info.json` è·å–ï¼‰

4. **æ¨¡å‹åˆ†æ**
   - æ¨¡å‹å¤§å°å¯¹æ¯”ï¼ˆåŸå§‹æ¨¡å‹ vs å‹ç¼©æ¨¡å‹ï¼‰
   - æ¨¡å‹å‹ç¼©æ•ˆæœï¼ˆé‡åŒ–ã€å‰ªæå‰åå¯¹æ¯”ï¼Œä» `compressed_models/` ç›®å½•è·å–ï¼‰
   - æœ€ä½³æ¨¡å‹ vs æœ€ç»ˆæ¨¡å‹æ€§èƒ½å¯¹æ¯”
   - æ¨¡å‹å¯¼å‡ºæ ¼å¼å…¼å®¹æ€§

5. **å®æ—¶æ•°æ®ä¼˜åŠ¿**
   - è¯´æ˜ç³»ç»Ÿæ”¯æŒå®æ—¶æ•°æ®ä¿å­˜ï¼Œæ¯è½®è®­ç»ƒå®Œæˆåç«‹å³ä¿å­˜
   - å±•ç¤ºå¦‚ä½•ä» `results/` ç›®å½•ä¸­æå–æ•°æ®è¿›è¡Œåˆ†æ
   - è¯´æ˜æœ€ä½³æ¨¡å‹è‡ªåŠ¨è·Ÿè¸ªæœºåˆ¶çš„ä¼˜åŠ¿

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **MPS Tensor float64 é”™è¯¯**
   - åŸå› : macOS MPS ä¸æ”¯æŒ float64
   - è§£å†³: ä»£ç å·²è‡ªåŠ¨å¤„ç†ï¼Œç¡®ä¿æ‰€æœ‰å¼ é‡ä½¿ç”¨ float32

2. **æ•°æ®è·¯å¾„é”™è¯¯**
   - ç¡®ä¿ `uci2_dataset/` ç›®å½•åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹
   - ç¡®ä¿åŒ…å« `feat_fold_0.csv`, `feat_fold_1.csv`, `feat_fold_2.csv` æ–‡ä»¶
   - æ£€æŸ¥ `federated_data/` ç›®å½•ä¸‹æ˜¯å¦æœ‰å„èŠ‚ç‚¹çš„ `train.pth` æ–‡ä»¶

3. **ç«¯å£è¢«å ç”¨**
   - ä¿®æ”¹ `federated_learning_visualization.py` ä¸­çš„ç«¯å£å·ï¼ˆé»˜è®¤ 5002ï¼‰

4. **èŠ‚ç‚¹æœªå‚ä¸è®­ç»ƒ**
   - æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å·²æ¿€æ´»ï¼ˆåœ¨å¯è§†åŒ–ç•Œé¢ä¸­ç‚¹å‡»"å¯åŠ¨èŠ‚ç‚¹"ï¼‰
   - æ£€æŸ¥ `devices.yaml` ä¸­çš„ `online_pattern` é…ç½®
   - æŸ¥çœ‹æ—¥å¿—ä¸­çš„èŠ‚ç‚¹å¯ç”¨æ€§ä¿¡æ¯

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **ç¡¬ä»¶æ„ŸçŸ¥**: ä½¿ç”¨ `devices.yaml` é…ç½®ä¸åŒè®¾å¤‡çš„è®¡ç®—èƒ½åŠ›ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è°ƒæ•´æ‰¹æ¬¡å¤§å°
2. **èµ„æºè°ƒåº¦**: è®­ç»ƒé¡ºåºæŒ‰åœ¨çº¿æ¨¡å¼ä¼˜å…ˆçº§è‡ªåŠ¨æ’åºï¼Œç¡®ä¿å¯é è®¾å¤‡ä¼˜å…ˆå‚ä¸
3. **æ¨¡å‹å‹ç¼©**: ä½¿ç”¨é‡åŒ–ã€å‰ªæç­‰æŠ€æœ¯å‡å°‘æ¨¡å‹å¤§å°å’Œæ¨ç†æ—¶é—´
4. **è‡ªé€‚åº”è°ƒæ•´**: æ ¹æ®ç½‘ç»œæ¡ä»¶å’Œè®¾å¤‡çŠ¶æ€åŠ¨æ€è°ƒæ•´è®­ç»ƒç­–ç•¥

## æ•°æ®é›†ä¿¡æ¯

### uci2_dataset

- **æ•°æ®æ¥æº**: UCI2æ•°æ®é›†
- **æ•°æ®æ ¼å¼**: CSVç‰¹å¾æ–‡ä»¶ï¼ˆ222ä¸ªç‰¹å¾ï¼‰
- **æ•°æ®è§„æ¨¡**: çº¦41ä¸‡æ ·æœ¬ï¼Œåˆ†å¸ƒåœ¨3ä¸ªfoldä¸­
- **ç‰¹å¾ç±»å‹**: PPGã€VPGã€APGä¿¡å·ç‰¹å¾ï¼Œæ—¶é—´åŸŸç‰¹å¾ï¼Œé¢ç§¯ç‰¹å¾ç­‰
- **æ ‡ç­¾**: ä½è¡€å‹æ ‡ç­¾ï¼ˆåŸºäºSP < 90 æˆ– DP < 60ï¼‰

è¯¦ç»†åˆ†æè¯·å‚è€ƒ: `Waveform-classification/help_files/UCI2_DATASET_ANALYSIS.md`

### æ•°æ®å‡†å¤‡æµç¨‹

1. `prepare_federated_data.py` åŠ è½½æ‰€æœ‰foldçš„CSVæ–‡ä»¶
2. åˆ›å»ºpatient_trialæ ¼å¼çš„ID
3. æ ¹æ®SPå’ŒDPåˆ›å»ºä½è¡€å‹æ ‡ç­¾
4. åˆå¹¶æ‰€æœ‰foldå¹¶éšæœºåˆ†å‰²ä¸ºè®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†
5. å°†è®­ç»ƒæ•°æ®åˆ†é…åˆ°å¤šä¸ªèŠ‚ç‚¹ï¼ˆnode_1, node_2, node_3ï¼‰

## ç³»ç»Ÿæ¶æ„è¯´æ˜

æœ¬ç³»ç»Ÿé‡‡ç”¨**è‡ªç ”è”é‚¦å­¦ä¹ æ¡†æ¶**ï¼Œä¸å†ä¾èµ– Fed-BioMedï¼š

- **å•è¿›ç¨‹æ¨¡æ‹Ÿ**: åœ¨ä¸€ä¸ª Python è¿›ç¨‹ä¸­æ¨¡æ‹Ÿå¤šä¸ªå®¢æˆ·ç«¯
- **é€»è¾‘æŠ½è±¡**: èŠ‚ç‚¹ï¼ˆnodeï¼‰å’Œç ”ç©¶è€…ï¼ˆresearcherï¼‰éƒ½æ˜¯é€»è¾‘æŠ½è±¡ï¼Œä¸æ˜¯ç‹¬ç«‹è¿›ç¨‹
- **ç›´æ¥è°ƒç”¨**: è®­ç»ƒé€»è¾‘é€šè¿‡å‡½æ•°è°ƒç”¨ç›´æ¥æ‰§è¡Œï¼Œæ— éœ€ç½‘ç»œé€šä¿¡
- **å®æ—¶ç›‘æ§**: é€šè¿‡ Flask + SocketIO å®ç°å®æ—¶çŠ¶æ€æ¨é€

è¯¦ç»†æ¶æ„è¯´æ˜è¯·å‚è€ƒ: `BIG_CHANGE.md`

## å‚è€ƒæ–‡çŒ®

- McMahan, B., et al. (2017). "Communication-Efficient Learning of Deep Networks from Decentralized Data"
- å·®åˆ†éšç§: Dwork, C. (2006). "Differential Privacy"
- UCI2æ•°æ®é›†: ç”¨äºä½è¡€å‹é¢„æµ‹çš„åŒ»ç–—æ³¢å½¢æ•°æ®é›†

## è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªç›¸åº”çš„å¼€æºè®¸å¯è¯ã€‚

## è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æäº¤Issueæˆ–è”ç³»é¡¹ç›®ç»´æŠ¤è€…ã€‚

---

**æœ€åæ›´æ–°**: 2025å¹´12æœˆ  
**ç‰ˆæœ¬**: v2.0 (è‡ªç ”è”é‚¦å­¦ä¹ æ¡†æ¶ç‰ˆæœ¬)
